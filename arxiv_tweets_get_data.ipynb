{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data\n",
    "\n",
    "This code connects to a global Twitter stream and listens for tweets that contain keyword 'arxiv'. In every such status, links that lead to an Arxiv paper are identified and paper's arxiv_id and version are extrected from the link. These are than saved in a raw_data.csv file, together with UTC time of the tweet. Data are gathered during 24 hour period.\n",
    "\n",
    "TODO:\n",
    "Retweets are problematic, they sometimes contain only the link to the original status (both in tweepy.status.retweeted_status.entities['urls'] and tweepy.status.retweeted_status.text). Solution would be to follow the link to the original status. Problem: chains of statuses (although depth 1 may be enough). Too much work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from IPython import display\n",
    "\n",
    "import urllib2 as ul                #to clear up redirections\n",
    "import re                #for validation of Arxiv urls\n",
    "\n",
    "import os\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To acces the Twitter stream, API acces keys are first necessary:\n",
    "\n",
    "https://www.digitalocean.com/community/tutorials/how-to-authenticate-a-python-application-with-twitter-using-tweepy-on-ubuntu-14-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#consumer key & consumer secret\n",
    "TWITTER_APP_KEY=        #Enter consumer key\n",
    "TWITTER_APP_SECRET=            #Enter consumer secret\n",
    "\n",
    "#acces token & acces token secret\n",
    "TWITTER_KEY=       #enter acces token\n",
    "TWITTER_SECRET=        #enter acces token secret\n",
    "\n",
    "#authentication\n",
    "auth = tweepy.OAuthHandler(TWITTER_APP_KEY, TWITTER_APP_SECRET)\n",
    "auth.set_access_token(TWITTER_KEY, TWITTER_SECRET)\n",
    "\n",
    "api=tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function that parses url of the paper and returns its id and version \n",
    "#Examples of urls of the paper with id 1612.03499 and version 2:\n",
    "#    https://arxiv.org/abs/1612.03499v2\n",
    "#    https://arxiv.org/pdf/1612.03499v2.pdf\n",
    "#    https://arxiv.org/abs/1612.03499?utm_source=dlvr.it&utm_medium=twitter\n",
    "#\n",
    "#if url doesn't match, returns False\n",
    "\n",
    "arxiv_url_re=re.compile(r'https?://arxiv\\.org/((abs)|(pdf))/\\d{4}\\.\\d{4,5}(v\\d)?')\n",
    "\n",
    "def id_from_url(url):\n",
    "    match=arxiv_url_re.search(url) #check if it's a valid arxiv address\n",
    "    if match:\n",
    "        arxiv_id=match.group().split('/')[-1]\n",
    "        try:\n",
    "            arxiv_id,version=arxiv_id.rsplit('v')\n",
    "        except ValueError:\n",
    "            version=0\n",
    "        return arxiv_id,int(version)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "datafile=open(os.path.join('data','raw_data.csv'),'a')\n",
    "csvwriter=csv.writer(datafile)\n",
    "\n",
    "def add_to_file(arxiv_id,version,created_at):\n",
    "    csvwriter.writerow(map(str,[arxiv_id,version,created_at]))\n",
    "    datafile.flush()\n",
    "\n",
    "#stream listener\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "    def __init__(self):\n",
    "        super( StreamListener, self ).__init__()\n",
    "        self.num=0            #number of processed statuses\n",
    "        self.num_added=0      #number of added papers (not every status contains paper)\n",
    "        self.started_at=datetime.utcnow()\n",
    "        \n",
    "    def on_status(self, status):\n",
    "        if (datetime.utcnow()-self.started_at).days>0:\n",
    "            print 'Listened for 24 hours, shutting down the listener.'\n",
    "            datafile.close()\n",
    "            return False\n",
    "        \n",
    "        self.num+=1\n",
    "        created_at=status.created_at\n",
    "        \n",
    "        display.clear_output()\n",
    "        #print '--------------------------------------------------------------'\n",
    "        print 'Tweets processed: '+str(self.num)+'        Papers added: '+str(self.num_added)\n",
    "        print 'Started at UTC: '+str(self.started_at)\n",
    "        print 'Last paper added:'\n",
    "        \n",
    "        #if status is retweeted, consider urls in the original status (because of truncating)\n",
    "        try:\n",
    "            if status.retweeted_status:\n",
    "                status=status.retweeted_status\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        for i in status.entities['urls']:\n",
    "            exp_url=i['expanded_url']\n",
    "            #try to see where is the url redirected to\n",
    "            try:\n",
    "                response= ul.urlopen(exp_url)\n",
    "            except:\n",
    "                url=exp_url\n",
    "            else:\n",
    "                url=response.geturl()\n",
    "            \n",
    "            #if the url leads to an arxiv paper, add it to the table\n",
    "            match=id_from_url(url)\n",
    "            if match:\n",
    "                arxiv_id,version=match\n",
    "                \n",
    "                self.num_added+=1\n",
    "                print arxiv_id,version,created_at\n",
    "                \n",
    "                add_to_file(arxiv_id,version,created_at)\n",
    "        \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            print 'twitter limit reached'\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "at_listener = StreamListener()\n",
    "stream = tweepy.Stream(auth=api.auth, listener=at_listener)\n",
    "stream.filter(track=['arxiv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
